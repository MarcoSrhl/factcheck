{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Fact-Checking System - Demo\n",
    "\n",
    "This notebook demonstrates the full fact-checking pipeline:\n",
    "1. **Triplet Extraction** - Extract (subject, predicate, object) from claims\n",
    "2. **Entity Linking** - Map entities to DBpedia URIs\n",
    "3. **Knowledge Base Query** - Verify claims against DBpedia\n",
    "4. **Neural Classification** - BERT-based verdict prediction\n",
    "5. **Final Verdict** - SUPPORTED / REFUTED / NOT ENOUGH INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "from src.triplet_extractor import TripletExtractor\n",
    "from src.entity_linker import EntityLinker\n",
    "from src.knowledge_query import KnowledgeQuery\n",
    "from src.fact_checker import FactChecker, format_result\n",
    "\n",
    "print('All modules loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Triplet Extraction\n",
    "\n",
    "We use spaCy dependency parsing to extract (subject, predicate, object) triplets from English sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = TripletExtractor()\n",
    "\n",
    "sentences = [\n",
    "    \"Paris is the capital of France\",\n",
    "    \"Barack Obama was born in Hawaii\",\n",
    "    \"Albert Einstein developed the theory of relativity\",\n",
    "    \"The Eiffel Tower is located in Paris\",\n",
    "    \"Tokyo is the capital of Japan\",\n",
    "]\n",
    "\n",
    "for sent in sentences:\n",
    "    triplets = extractor.extract(sent)\n",
    "    print(f'\\n\"{sent}\"')\n",
    "    for s, p, o in triplets:\n",
    "        print(f'  Subject: {s}')\n",
    "        print(f'  Predicate: {p}')\n",
    "        print(f'  Object: {o}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity Linking\n",
    "\n",
    "Map extracted entities to their DBpedia URIs using the DBpedia Lookup API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = EntityLinker()\n",
    "\n",
    "entities = [\"Paris\", \"France\", \"Barack Obama\", \"Hawaii\", \"Eiffel Tower\", \"Albert Einstein\", \"Tokyo\", \"Japan\"]\n",
    "\n",
    "for entity in entities:\n",
    "    uri = linker.link(entity)\n",
    "    print(f'{entity:20s} -> {uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Knowledge Base Query\n",
    "\n",
    "Verify relations between entities using DBpedia SPARQL and JSON endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kq = KnowledgeQuery()\n",
    "\n",
    "pairs = [\n",
    "    (\"http://dbpedia.org/resource/Paris\", \"http://dbpedia.org/resource/France\"),\n",
    "    (\"http://dbpedia.org/resource/Barack_Obama\", \"http://dbpedia.org/resource/Hawaii\"),\n",
    "    (\"http://dbpedia.org/resource/Eiffel_Tower\", \"http://dbpedia.org/resource/Paris\"),\n",
    "    (\"http://dbpedia.org/resource/Tokyo\", \"http://dbpedia.org/resource/Japan\"),\n",
    "]\n",
    "\n",
    "for subj, obj in pairs:\n",
    "    result = kq.verify_triplet(subj, obj)\n",
    "    subj_name = subj.split('/')[-1].replace('_', ' ')\n",
    "    obj_name = obj.split('/')[-1].replace('_', ' ')\n",
    "    print(f'\\n{subj_name} <-> {obj_name}')\n",
    "    print(f'  Found: {result[\"found\"]} (via {result[\"method\"]})')\n",
    "    for p in result['predicates'][:3]:\n",
    "        print(f'  Predicate: {p.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Pipeline - Fact Checking\n",
    "\n",
    "Run the complete pipeline on 10 example claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full pipeline (with neural model if available, otherwise KB-only)\n",
    "import os\n",
    "model_path = '../models/fact_checker'\n",
    "use_neural = os.path.exists(model_path)\n",
    "checker = FactChecker(model_path=model_path if use_neural else None, use_neural=use_neural)\n",
    "print(f'Pipeline loaded (neural model: {\"enabled\" if use_neural else \"disabled - KB only\"})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = [\n",
    "    # True claims\n",
    "    \"Paris is the capital of France\",\n",
    "    \"Barack Obama was born in Hawaii\",\n",
    "    \"The Eiffel Tower is located in Paris\",\n",
    "    \"Albert Einstein developed the theory of relativity\",\n",
    "    \"Tokyo is the capital of Japan\",\n",
    "    # False claims\n",
    "    \"The Earth is flat\",\n",
    "    \"Napoleon was born in England\",\n",
    "    \"Mars is the largest planet in the solar system\",\n",
    "    # Ambiguous claims\n",
    "    \"Chocolate causes acne\",\n",
    "    \"Dogs can sense earthquakes before they happen\",\n",
    "]\n",
    "\n",
    "expected = [\n",
    "    \"SUPPORTED\", \"SUPPORTED\", \"SUPPORTED\", \"SUPPORTED\", \"SUPPORTED\",\n",
    "    \"REFUTED\", \"REFUTED\", \"REFUTED\",\n",
    "    \"NOT ENOUGH INFO\", \"NOT ENOUGH INFO\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for claim in claims:\n",
    "    result = checker.check(claim)\n",
    "    results.append(result)\n",
    "    print('=' * 60)\n",
    "    print(format_result(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics\n",
    "\n",
    "Evaluate the pipeline's performance against expected verdicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "predicted = [r['verdict'] for r in results]\n",
    "\n",
    "print('Claim-by-claim results:')\n",
    "print(f'{\"Claim\":50s} {\"Expected\":18s} {\"Predicted\":18s} {\"Match\"}')\n",
    "print('-' * 100)\n",
    "for claim, exp, pred in zip(claims, expected, predicted):\n",
    "    match = 'OK' if exp == pred else 'MISS'\n",
    "    print(f'{claim:50s} {exp:18s} {pred:18s} {match}')\n",
    "\n",
    "# Overall metrics\n",
    "labels = ['SUPPORTED', 'REFUTED', 'NOT ENOUGH INFO']\n",
    "acc = accuracy_score(expected, predicted)\n",
    "print(f'\\n{\"=\" * 50}')\n",
    "print(f'Accuracy: {acc:.2%}')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(expected, predicted, labels=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution\n",
    "print('\\nConfidence distribution by verdict:')\n",
    "for verdict in labels:\n",
    "    confs = [r['confidence'] for r in results if r['verdict'] == verdict]\n",
    "    if confs:\n",
    "        avg_conf = sum(confs) / len(confs)\n",
    "        print(f'  {verdict:18s}: avg={avg_conf:.3f}, min={min(confs):.3f}, max={max(confs):.3f} (n={len(confs)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Try Your Own Claim\n",
    "\n",
    "Enter any English claim to fact-check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_claim = \"London is the capital of the United Kingdom\"\n",
    "result = checker.check(custom_claim)\n",
    "print(format_result(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
